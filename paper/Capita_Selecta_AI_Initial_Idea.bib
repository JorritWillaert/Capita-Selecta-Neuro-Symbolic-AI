Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@book{sys1and2,
abstract = {The phenomenal New York Times Bestseller by Nobel Prize-winner Daniel Kahneman, Thinking Fast and Slow offers a whole new look at the way our minds work, and how we make decisions. Why is there more chance we'll believe something if it's in a bold type face? Why are judges more likely to deny parole before lunch? Why do we assume a good-looking person will be more competent? The answer lies in the two ways we make choices: fast, intuitive thinking, and slow, rational thinking. This book reveals how our minds are tripped up by error and prejudice (even when we think we are being logical), and gives you practical techniques for slower, smarter thinking. It will enable to you make better decisions at work, at home, and in everything you do.},
address = {London},
author = {Kahneman, Daniel},
isbn = {9780141033570},
keywords = {Cognitieve psychologie},
publisher = {Penguin Books},
title = {{Thinking, fast and slow}},
year = {2012}
}
@article{model_architecture,
author = {Theodoropoulos, Christos},
file = {:home/jorrit/Downloads/IR_SE_project_2021_2022.pdf:pdf},
journal = {Toledo},
pages = {1--5},
title = {{Information Retrieval and Search Engines [ H02C8b ] Project Visual Question Answering}},
year = {2022}
}
@misc{deepproblog_code,
author = {Manhaeve, Robin},
title = {{ML-KULeuven/deepproblog: DeepProbLog is an extension of ProbLog that integrates Probabilistic Logic Programming with deep learning by introducing the neural predicate.}},
url = {https://github.com/ML-KULeuven/deepproblog},
urldate = {2022-03-09}
}
@inproceedings{deepproblog,
abstract = {We introduce DeepProbLog, a probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques can be adapted for the new language. Our experiments demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples.},
archivePrefix = {arXiv},
arxivId = {1805.10872},
author = {Manhaeve, Robin and Kimmig, Angelika and Duman{\v{c}}i{\'{c}}, Sebastijan and Demeester, Thomas and {De Raedt}, Luc},
booktitle = {Advances in Neural Information Processing Systems},
doi = {10.48550/arxiv.1907.08194},
eprint = {1805.10872},
file = {:home/jorrit/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Manhaeve et al. - 2019 - Neural Probabilistic Logic Programming in DeepProbLog.pdf:pdf},
issn = {10495258},
keywords = {learning and reasoning,logic,neural networks,neuro-symbolic integration,probabilistic logic programming,probability},
month = {jul},
pages = {3749--3759},
title = {{Deepproblog: Neural probabilistic logic programming}},
url = {https://arxiv.org/abs/1907.08194v2},
volume = {2018-Decem},
year = {2018}
}
@article{clevr_dataset,
abstract = {When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover shortcomings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations.},
archivePrefix = {arXiv},
arxivId = {1612.06890},
author = {Johnson, Justin and Fei-Fei, Li and Hariharan, Bharath and Zitnick, C. Lawrence and {Van Der Maaten}, Laurens and Girshick, Ross},
doi = {10.1109/CVPR.2017.215},
eprint = {1612.06890},
file = {:home/jorrit/Data/KU Leuven/Semester 11/Capita Selecta AI H05N0a/Initial idea/papers/clevr_dataset_paper.pdf:pdf;:home/jorrit/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson et al. - 2017 - CLEVR A diagnostic dataset for compositional language and elementary visual reasoning(2).pdf:pdf},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
pages = {1988--1997},
title = {{CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning}},
volume = {2017-Janua},
year = {2017}
}
@misc{sort_of_clevr_dataset,
author = {Heecheol, Kim},
title = {{kimhc6028/relational-networks: Pytorch implementation of "A simple neural network module for relational reasoning" (Relational Networks)}},
url = {https://github.com/kimhc6028/relational-networks},
urldate = {2021-11-28}
}
