\documentclass[english]{sobraep}
\usepackage{minted}

\title{Visual Question Answering with DeepProbLog}

\author{Jorrit Willaert$^{1}$ \\
	\normalsize $^{1}$Catholic University of Leuven, Leuven -- Belgium \\
	\normalsize e-mail: jorrit.willaert@student.kuleuven.be
}

\begin{document}

\maketitle
% TODO also maybe include some results from other papers. (E.g. see paper of relational-networks)

\begin{abstract}
	This report focusses on Visual Question Answering, where a Neuro Symbolic AI approach with a knowledge base is compared with a purely neural network based approach. From the experiments, it follows that DeepProbLog, the framework used for the Neuro Symbolic AI approach, is able to achieve the same accuracy as the pure neural network based approach with almost 200 times less iterations. Clearly, the training is much more targeted, but however, comes at a cost. The algebraic operators internal to DeepProbLog are extremely costly and hence the actual training time is considerably slower. Another drawback of DeepProbLog is that no easy speedups can be achieved, since the algebraic operators only work on CPU's, and hence cannot benefit from accelerators such as GPU's.
\end{abstract}

\begin{keywords}
	Neuro Symbolic AI, Visual Question Answering, DeepProbLog, Problog, Convolutional Neural Networks
\end{keywords}

\section{INTRODUCTION}
The Neuro Symbolic AI field is interested in building a bridge between the robustness of probabilistic knowledge, with the well-known popularity and proven strengths of deep neural networks. DeepProbLog \cite{deepproblog} offers this ability, by using both the strengths of neural networks (i.e. system 1, typical subconscious tasks such as visual recognition, the processing of languages, \dots), along with the strengths of rule-based probabilistic systems (i.e. system 2, slow, sequential thinking such as the derivation of a proof) \cite{sys1and2}. 

This paper elaborates on an application that requires both systems to be used, namely Visual Question Answering. System 1 will be required in order to gain an understanding of the image under investigation, with in particular their shapes and colors. System 2, on the other hand, will use this extracted information for deriving certain properties of objects\footnote{For example, finding the shape of the green object, or deriving if it is located on the left hand side of the image.}, or even for capturing the relations\footnote{Here, one could think of counting the number of circles in the image.} between the objects. 

\section{ORGANIZATION OF THE PAPER}
This paper will first provide some necessary background in Section \ref{sec:literature_survey} on certain types of datasets that are typically used for Visual Question Answering purposes, along with introducing some results of other researchers. Then, Section \ref{sec:approach} will dive deeper in the different components constituting the overall system. A main focus of this paper is to outline the advantages of using a Neuro Symbolic AI approach (offered by the DeepProbLog framework), compared to a purely neural network based approach. These experiments are listed in Section \ref{sec:experiments}. Finally, the main findings of this paper are repeated in Section \ref{sec:conclusions}.

\section{LITERATURE SURVEY}
\label{sec:literature_survey}
The application focuses on Visual Question Answering (VQA), for which huge datasets are present, along with very sophisticated methods. The best known dataset for VQA is CLEVR \cite{clevr_dataset}, which contains 100k images accompanied by one million questions. An example image is given in Figure \ref{fig:sample_image_clevr}, while example questions are:
\begin{itemize}
    \item Are there an equal number of large things and metal spheres?
    \item What size is the cylinder that is left of the brown metal thing that is left of the big sphere?
    \item How many objects are either small cylinders or metal things?
\end{itemize}

\begin{figure}[htp]
    \begin{center}
    \includegraphics[width=0.3\textwidth]{clevr.jpg}
    \captionsetup{justification=centering}
    \caption{A sample image from the CLEVR dataset \cite{clevr_dataset}}
    \label{fig:sample_image_clevr}
    \end{center}
\end{figure}

Clearly, both system 1 and system 2 are actively used when answering these questions. One could wonder if neural networks alone could answer these questions without having an explicit system 2 encoding (i.e. the rule based knowledge base). Intuitively, it makes sense that if certain facts of the world are known\footnote{Facts can be encoded, e.g. counting the number of spheres is simply a matter of detecting all the spheres in the image, after which a mathematical summation is a statement in the knowledge base.}, learning can proceed much more quickly\footnote{Not to say that learning might even be impossible if a lot of background knowledge is required.}. Seen from an optimization viewpoint, errors made during prediction in this setup can be targeted exactly, which makes the optimization process more targeted as well, and hence more efficient. Finally, this paper also provides evidence for these statements, since in subsection \ref{subsec:experiments_NN_vs_deepproblog}, the comparison between a VQA implementation with DeepProbLog is made with a purely neural network based approach. 

This paper is inspired on the CLEVR dataset, but uses however a much more simplified version. In essence, it is almost like the Sort-of-CLEVR dataset \cite{sort_of_clevr_dataset}. This Sort-of-CLEVR dataset contains images as in Figure \ref{fig:sample_image_sort_of_clevr}, while asking questions such as:
\begin{itemize}
    \item Non-relational questions: the shape, horizontal or vertical location of an object.
    \item Relational questions: shape of the closest/furthest object to the object under investigation, or the number of objects with the same shape.
\end{itemize}

\begin{figure}[htp]
    \begin{center}
    \fbox{\includegraphics[width=0.25\textwidth]{sort_of_clevr.png}}
    \captionsetup{justification=centering}
    \caption{A sample image from the Sort-of-CLEVR dataset \cite{sort_of_clevr_dataset}}
    \label{fig:sample_image_sort_of_clevr}
    \end{center}
\end{figure}

As illustrated earlier, both system 1 and system 2 are required for these types of VQA's.

A. Santoro et al. conducted similar experiments with the Sort-of-CLEVR dataset as in this paper, where they were able to achieve an accuracy of 63\% on relational questions with CNN's. In contrast, an accuracy of 94\% for both relational and non-relational questions was achieved with CNN's, complemented with an RN. For them, augmenting the model with a relational module, such as an RN, turned out to be sufficient to overcome the hurdle of solving relational questions \cite{sort_of_clevr_dataset}. They were the only researchers who undertook experiments on a dataset resembling the one from this paper, and hence are the only reference point.

Finally, since this application uses DeepProbLog, quite some time was spent in digesting the DeepProbLog paper \cite{deepproblog}, along with understanding the  examples provided in the code repository \cite{deepproblog_code}.

\section{APPROACH}
\label{sec:approach}
The implementation process involved three main parts:
\begin{enumerate}
    \item Generation of the data.
    \item Linking the data and controlling the training process in pure Python code.
    \item Creation of the logical part with DeepProbLog statements.
\end{enumerate}

\subsection{Generation of the data}
As mentioned in Section \ref{sec:literature_survey}, the data used in this application is based on the Sort-of-CLEVR dataset, with one extra simplification. Given that the logical part will have to decide whether an object is for example located on the left side of an image, the neural network will have to convey positional information to the logical part. Hence, each discrete position will have to be encoded by a possible outcome of the neural network. Therefore, objects may only be located at certain positions in a grid. In this paper, results on a grid of 2x2 and 6x6 are discussed.

The data generator that was used for the creation of the Sort-of-CLEVR dataset has been modified in order to position objects in the mentioned grid positions \cite{sort_of_clevr_dataset}. An example of a generated image is given in Figure \ref{fig:sample_image_own_dataset}, where the difference with Figure \ref{fig:sample_image_sort_of_clevr} is the grid-layout.

\begin{figure}[htp]
    \begin{center}
    \fbox{\includegraphics[width=0.25\textwidth]{sample_image_dataset.png}}
    \captionsetup{justification=centering}
    \caption{A sample image from the dataset that has been used for this application}
    \label{fig:sample_image_own_dataset}
    \end{center}
\end{figure}

Each specified color will have an object located somewhere in the grid, of which the shape can be a square or a circle.

These images are accompanied with a question about a random object, which can be one of the following:
\begin{itemize}
    \item Non-relational --- What is the shape of this object\footnote{The shape will be either a square or a circle.}?
    \item Non-relational --- Is this object located on the left hand side of the image?
    \item Non-relational --- Is this object located on the bottom side of the image?
    \item Relational --- How many objects have the same shape as this object?
\end{itemize}

These questions are encoded in a vector encoding, after which they are stored in a CSV file, along with the expected answers. A training and test dataset has been generated beforehand, in order to make the training process more efficient. 

\subsection{Controlling the training process}
The overall training process is controlled via the Python API of DeepProbLog, along with general PyTorch implementations of the CNN's.
First of all, CNN's are defined with PyTorch. A relatively simple network is used, where the input is given as a square RGB image of 100 pixels wide, which is transformed by the CNN into 72 output features for the 6x6 grid\footnote{For the 2x2 grid example, 8 output features are required.}. Each color that is present in the image has its accompanied CNN network, hence the 72 output features encode the possible positions of the object with that color, along with their shape, which can be either square or circular ($6 \cdot 6 \cdot 2 = 72$).

The final thing (besides the logical rule encodings) required before commencing the training process, are the data loaders. The most challenging part here is the transformation from the generated data to specific query mappings and their outcome. 

\subsection{Logical rule encodings}
Once the CNN belonging to a specific color has determined the position and the shape of that object, logical rules can deduce whether this object is located on the left hand side of the image, on the bottom side, and how many objects have the same shape. The logical rule program has been listed in Appendix \ref{appendix:logical_rule_encodings}.

\section{EXPERIMENTS}
\label{sec:experiments}
The main focus of this paper is to outline the advantages of using a Neuro Symbolic AI approach (offered by the DeepProbLog framework), instead of a purely neural network based approach. Therefore, a neural network based approach had to be implemented. Not all details will be listed here, but the main idea is that the image has to be fused with the question, after which a prediction can be made\footnote{Possible answers on the questions are: rectangle, circle, yes, no, 1, 2, 3, 4, 5 and 6. Hence, the neural network will have 10 output nodes. Care has been taken for class skew, by introducing weights in the loss function.}. The general structure of this network is given in Figure \ref{fig:pure_nn_network}.

\begin{figure}[H]
    \begin{center}
    \includegraphics[width=0.45\textwidth]{pure_nn_architecture.png} 
    \captionsetup{justification=centering}
    \caption{Abstract representation of the purely neural network based architecture \cite{model_architecture}}
    \label{fig:pure_nn_network}
    \end{center}
\end{figure}

\subsection{COMPARISONS WITH PURE SYSTEM 1 APPROACHES}
\label{subsec:experiments_NN_vs_deepproblog}
\subsubsection{Experiment --- 2x2 grid}
The loss curves of both the DeepProbLog approach, as well as the purely neural network based approach, are visualized respectively in Figure \ref{fig:loss_curve_deepproblog_2x2} and Figure \ref{fig:loss_curve_pure_NN_2x2}.

\begin{figure}[htp]
    \begin{center}
    \includegraphics[width=0.45\textwidth]{loss_curve_deepproblog_2x2.png} 
    \captionsetup{justification=centering}
    \caption{DeepProbLog 2x2: Loss curve}
    \label{fig:loss_curve_deepproblog_2x2}
    \end{center}
\end{figure}

\begin{figure}[htp]
    \begin{center}
    \includegraphics[width=0.45\textwidth]{loss_curve_pure_NN_2x2.png} 
    \captionsetup{justification=centering}
    \caption{Pure NN based approach 2x2: Loss curve}
    \label{fig:loss_curve_pure_NN_2x2}
    \end{center}
\end{figure}
An extremely important remark to be made is the difference between `number of iterations' and `number of epochs'. By the number of iterations, the number of forward and backward passes of a batch (with size 32) is meant, whereas the number of epochs denotes the number of times all the images of the training set are forward and backwardly passed. In this application, a training size of 10 000 was used, hence one epoch consists of 312.5 iterations.

From the loss curves, it is clear that both approaches seem to converge to an accuracy of 100\%. However, DeepProbLog only requires around 40 iterations, whereas the purely neural network based approach requires at least 7 800 iterations. This again demonstrates the value of Neuro Symbolic AI.

On the other hand, one has to consider the actual running times for those iterations. DeepProbLog takes around 10 minutes to finish its 160 iterations, while the purely neural network based approach only requires around 5 minutes to finish 7 800 iterations. Taking into consideration that the purely neural network based approach can be accelerated massively (by using GPU's), while DeepProbLog can't\footnote{DeepProbLog offers the ability to send the CNN to a GPU for faster inference, however, the arithmetic operators (i.e. semirings) of DeepProbLog work on the CPU. These arithmetic operators possess by far the highest computational cost.}, it is clear that DeepProbLog trains much more targeted, but is computationally extremely heavy (at least for now).

\subsubsection{Experiment --- 6x6 grid}
The loss curves for the 6x6 experiment of DeepProbLog and the neural network based approach are depicted in respectively Figure \ref{fig:loss_curve_deepproblog_6x6} and Figure \ref{fig:loss_curve_pure_NN_6x6}.

\begin{figure}[htp]
    \begin{center}
    \includegraphics[width=0.45\textwidth]{loss_curve_deepproblog_6x6.png} 
    \captionsetup{justification=centering}
    \caption{DeepProbLog 6x6: Loss curve}
    \label{fig:loss_curve_deepproblog_6x6}
    \end{center}
\end{figure}

\begin{figure}[htp]
    \begin{center}
    \includegraphics[width=0.45\textwidth]{loss_curve_pure_NN_6x6.png} 
    \captionsetup{justification=centering}
    \caption{Pure NN based approach 6x6: Loss curve}
    \label{fig:loss_curve_pure_NN_6x6}
    \end{center}
\end{figure}

In these experiments, the training time of the purely neural network based approach was 20 minutes\footnote{For fair speed estimation, training has been conducted on the CPU.}, while the training time of the DeepProbLog approach was a little under eight hours\footnote{However, it should be mentioned that approximately half of the time was spent on calculating the accuracy each time, since the whole testing set had to be forwarded through the network, while for the training iterations this is only one batch.}.

The most important observation here is that the purely neural network approach overfits quickly and also achieves a considerably lower accuracy (68\% instead of 75\% for DeepProbLog). Another important remark is the fact that both approaches are clearly not longer able to attain an accuracy of 100\%. However, if the DeepProbLog network could train longer, it would be able to converge somewhat further.

In Figure \ref{fig:confusion_matrix_6x6_deepproblog} and Figure \ref{fig:confusion_matrix_6x6_pure_nn}, the confusion matrices are depicted in order to show where typical mistakes are made.

\begin{figure}[htp]
    \begin{center}
    \includegraphics[width=0.45\textwidth]{confusion_matrix_6x6_deepproblog.png} 
    \captionsetup{justification=centering}
    \caption{The confusion matrix of the 6x6 dataset from DeepProbLog}
    \label{fig:confusion_matrix_6x6_deepproblog}
    \end{center}
\end{figure}

\begin{figure}[htp]
    \begin{center}
    \includegraphics[width=0.45\textwidth]{confusion_matrix_6x6_pure_NN.png} 
    \captionsetup{justification=centering}
    \caption{The confusion matrix of the 6x6 dataset from the purely neural network approach}
    \label{fig:confusion_matrix_6x6_pure_nn}
    \end{center}
\end{figure}

DeepProbLog naturally will not make any `nonsense' mistakes such as answering `yes' to the question `What shape has the object under investigation?', since the possible correct answers are encoded in the program. However, the purely neural network based approach has learned perfectly to link the possible answers to the questions.

Another observation is that DeepProbLog is much better in answering the questions `What shape has the object under investigation?' and `Is the object located on the left hand side (or on the bottom side) of the image?' than a purely neural network approach is. This makes sense, since DeepProbLog can use its knowledge base to derive these properties, once the position (and shape) of the given object is determined. The observation that a pure neural network based approach has a much harder time to distinguish these cases, was also observed by A. Santoro et al. \cite{sort_of_clevr_dataset}, where they achieved an accuracy of 63\% on these questions with a pure neural network based approach. DeepProbLog was not able to achieve the accuracy of 94\% that these researchers achieved on all questions with an added RN module, which may be due to the inherent training cost of the algebraic operators, as well as due to less resources, less hyperparameter tuning, and an absence of RN modules, among many other unknown variables.

Regarding the relational question: `How many objects have the same shape as the object under investigation?', a lot more confusion in both approaches is going on. DeepProbLog will typically be able to come close to the correct answer, but may make some `off-by-one' mistakes\footnote{I.e. one CNN that is mispredicting the shape of its object.}. The purely neural network based approach does also in this perspective a little worse. It is also plausible that in this approach, the neural network may have observed that due to probabilistic reasons, there are likely three or four equal objects (inclusive the one under investigation), and hence prefers such an answer.

\section{CONCLUSIONS}
\label{sec:conclusions}
The strengths of the Neuro Symbolic AI field has been demonstrated in the context of Visual Question Answering. By using DeepProbLog, the chosen framework for the Neuro Symbolic AI task, it became clear that almost 200 times less iterations are required to achieve the same accuracy as a purely neural network based approach. However, due to the costly algebraic operators, the total training time of the DeepProbLog approach was considerably slower, compared to the purely neural network based approach. 

Important to notice, however, is that DeepProbLog performs a lot better on the non-relational questions. This because the knowledge base can derive these properties much more accurately, while a purely neural network based approach has more difficulties with such derivations.

Hence, a lot of value can be seen in Neuro Symbolic AI approaches, despite the costly algebraic operators. Especially for tasks where the knowledge base is much larger, these approaches can make the difference between being able to learn a certain task or not. Over time, speedups for these algebraic operators could probably be developed, which opens the road to even more applications.

\bibliographystyle{bib_sobraep}
\bibliography{Capita_Selecta_AI_Initial_Idea} 

\section*{APPENDIX}
\subsection{Logical rule encodings}
Note: it has been tried to use cuts (with the `cut' library), given that the neural network is seemingly invoked again if the first of a dual predicate fails. However, this turned out to not yield any performance improvement and has been abandoned.
\label{appendix:logical_rule_encodings}
\inputminted[breaklines]{prolog}{"/home/jorrit/Data/KU Leuven/Semester 12/Capita Selecta H05N0a/deepproblog/src/deepproblog/examples/SORTOFCLEVR/model.pl"}

%\balance

\end{document}